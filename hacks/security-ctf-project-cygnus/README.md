
# GCP Security CTF Project Cygnus

## Introduction

Welcome, agent, to Project Cygnus. This is a GCP Capture the Flag "CTF" Challenge Style.

You've just been dropped into the cloud environment of "Cygnus Corp," the galaxy's fastest-growing (and most chaotic) tech startup. They move fast, break things, and their security policy seems to be written on a napkin that’s currently on fire. They’ve built a revolutionary data processing pipeline that’s poised to change the world... or get them completely owned by the first person who rattles the doorknob.

That’s where you come in.

You are an elite cyber operative, a digital ghost, a "security professional" (which is a fancy way of saying you get paid to break stuff). Your mission, should you choose to accept it, is to navigate this minefield of misconfigurations, find the security holes before the actual bad guys do, and trace the path from a simple public file to the company’s crown jewels.

Forget everything you know about boring tutorials. This is a digital safari. A high-stakes puzzle box. A playground of things you should never do in a real production environment. So grab your keyboard, fire up your terminal, and let's go see what skeletons are hiding in Cygnus's cloud.

## Learning Objectives

This CTF is designed to provide practical, hands-on experience with a wide array of Google Cloud services. Upon completion, you will be able to:

1. **Cloud Storage & IAM:**

   - Audit and identify public-facing buckets using gcloud storage commands and the GCP Console.
   - Analyze IAM policies (roles/storage.objectViewer) to determine the impact of misconfigurations like granting access to allUsers.
   - Understand how Data Access audit logs are configured and recognize the security risk of having them disabled.

1. **Cloud Functions & Event-Driven Architecture:**

   - Inspect a deployed Cloud Function to identify its trigger mechanism (Eventarc), runtime, and assigned Service Account.
   - Trace the event flow from a Cloud Storage upload, through a Pub/Sub notification, to an Eventarc trigger that invokes a function.

1. **Software Supply Chain Security (Artifact Registry & Cloud Build):**

   - Analyze a Dockerfile to identify security weaknesses, such as the use of non-specific or un-hardened base images (python:3.9-slim).
   - Create and manage a private Docker repository using Artifact Registry.
   - Use the Docker CLI and gcloud auth configure-docker to pull from Docker Hub, tag, and push container images to a private Artifact Registry repository.
   - Author a cloudbuild.yaml file from scratch to define a container build pipeline using Cloud Build.

1. **Serverless Application Deployment (Cloud Run):**

   - Deploy a container image from Artifact Registry to Cloud Run as a new serverless application.
   - Configure a Cloud Run service for public access by correctly setting its IAM policy to allow unauthenticated invocations (roles/run.invoker for allUsers).

1. **Cloud Security Posture Management (Security Command Center):**

   - Navigate Security Command Center (SCC) to view and filter active security findings.
   - Recognize and interpret a high-priority finding, such as the "Public bucket ACL" finding generated by SCC.

1. **AI & Machine Learning (Vertex AI):**

   - Create and launch a custom training job on Vertex AI, using a pre-built container image from Artifact Registry.

## Challenges

- Challenge 1: Secure the Foundation and Data Governance
  - Find the initial entry point, a public Cloud Storage bucket, and analyze the Cloud Function it triggers.
- Challenge 2: Supply Chain Vulnerability
  - Inspect the application's source code, identify a Dockerfile vulnerability, and prepare a secure base image in Artifact Registry.
- Challenge 3: Build the Container
  - Create a `cloudbuild.yaml` to define a CI pipeline that builds the application container.
- Challenge 4: Deploy and Expose the Application
  - Deploy the container to Cloud Run and configure it for public access.
- Challenge 5: Evasion and Exfiltration
  - Use Security Command Center to identify and interpret the security findings in the project.

## Prerequisites

- **Your Digital Sandbox:** A Google Cloud Project where you have permission to play. We’ve set up the basics; your job is to make the glorious mess.
- **Your Magic Wand (and Crowbar):** Access to the Cloud Shell or a local terminal with the gcloud SDK installed. This is where you'll cast the spells.
- **A Map and a Compass:** You should know how to navigate a command line without accidentally typing rm -rf /. You've heard of "the cloud," and you know it’s just someone else's computer.
- **A Healthy Dose of Curiosity:** Your most important tool. A burning desire to poke things with a digital stick to see what happens. Don't be afraid to break things—that's literally the whole point.
- **Cyber-Fuel:** Coffee, tea, energy drinks, or just pure, unadulterated spite. Whatever keeps your fingers flying.

You are now ready. Good luck, agent. Try not to get caught.

## Contributors

- Mohamed Fawzi
- Murat Ekan

## Challenge 1: Secure the Foundation and Data Governance

### Introduction

Every security assessment begins with reconnaissance. Your first objective is to survey the digital landscape of Cygnus Corp and find a way in. In the cloud, the "front door" is often an unintentionally public resource. Your task is to find this initial foothold and understand what automated processes are connected to it.

### Description

You will begin by scanning for publicly accessible Cloud Storage buckets. Once you identify a public bucket, you will need to deduce its purpose. By observing the environment, you will discover that uploads to this bucket trigger a serverless function. Your goal is to identify this function and analyze its configuration, which will provide the necessary intelligence to proceed to the next stage.

### Success Criteria

- You can prove that the [PROJECT-ID]-cygnus-raw-telemetry bucket is publicly readable to allUsers.
- You have identified the cygnus-dlp-trigger Cloud Function as the service that processes uploads to the public bucket.
- You can identify the specific runtime Service Account assigned to this function.

### Learning Resources

- [Making Data Public (Cloud Storage)](https://cloud.google.com/storage/docs/access-control/making-data-public)
- [Cloud Functions Overview](https://cloud.google.com/functions/docs/overview)
- [Cloud Storage Triggers for Functions](https://cloud.google.com/functions/docs/calling/storage)

## Challenge 2: Supply Chain Vulnerability

### Introduction

You've identified the initial data pipeline. Now, it's time to investigate the application code that will eventually be part of this pipeline. A common attack vector is the software supply chain—the dependencies and base images that an application is built upon. A weakness here can compromise the entire system.

### Description

Your task is to analyze the application's source code, which is stored in a Cloud Source Repository within the project. You will inspect its Dockerfile to identify a critical security weakness in its base image. To remediate this (as part of a simulated "blue team" action), you will create your own secure, private repository in Artifact Registry and populate it with a "blessed" version of the base image.

### Success Criteria

- You can identify the FROM python:3.9-slim line in the Dockerfile as the specific supply chain vulnerability.
- You have successfully created a new, private Docker repository in Artifact Registry named cygnus-approved-images.
- You have successfully pulled the python:3.9-slim image from Docker Hub, re-tagged it, and pushed it into your cygnus-approved-images repository.

### Learning Resources

- [Creating Docker Repositories (Artifact Registry)](https://cloud.google.com/artifact-registry/docs/docker/create-repos)
- [Pushing and Pulling Docker Images (Artifact Registry)](https://cloud.google.com/artifact-registry/docs/docker/pushing-and-pulling)
- [Cloud Source Repositories Quickstart:](https://cloud.google.com/source-repositories/docs/quickstart)

## Challenge 3: Build the Container

### Introduction

With your supply chain clean (or at least, understood), it's time to build the application. This stage focuses on creating the automated process that transforms your source code into a runnable container image. You'll be setting up the continuous integration (CI) part of a CI/CD pipeline.

### Description

The `cygnus-processor-app` source code repository is missing its build instructions. Your task is to create a `cloudbuild.yaml` file that tells Google Cloud Build how to construct a container image from the application's source code. You will then trigger this build process, and verify that the resulting image is correctly stored in your Artifact Registry.
  
### Success Criteria

- You have created a valid `cloudbuild.yaml` file and pushed it to the 'cygnus-processor-app' repository.
- You have successfully run a Cloud Build job triggered by your new `cloudbuild.yaml`.
- A container image named `cygnus-processor:1.0` has been successfully built and is stored in your `cygnus-approved-images` repository.
  
### Learning Resources

- [Building container images with Cloud Build](https://cloud.google.com/build/docs/building/build-containers)
- [Creating a basic `cloudbuild.yaml`](https://cloud.google.com/build/docs/build-config-file-schema)

## Challenge 4: Deploy and Expose the Application

### Introduction

You've built the container; now it's time to deploy it and make it accessible. This stage focuses on deploying your containerized application to a serverless platform and configuring its network access. This represents the "continuous deployment" (CD) part of your pipeline.

### Description

You will take the container image you built in the previous stage and deploy it to Google Cloud Run. This will create a new, publicly accessible web service. You will also confirm the absence of advanced network security controls like Web Application Firewalls (WAFs) or API Gateways, indicating an additional layer of vulnerability.
  
### Success Criteria

- You have deployed the cygnus-processor:1.0 container image to a new Cloud Run service named cygnus-prediction-service.
- Your cygnus-prediction-service is configured for public access (allowing unauthenticated invocations).
- The URL for your Cloud Run service is accessible from a web browser without requiring authentication.
- You have verified that no WAF or API Gateway policies are configured for the service.
  
### Learning Resources

- [Deploying a container to Cloud Run](https://cloud.google.com/run/docs/deploying)
- [Allowing public (unauthenticated) access to a Cloud Run service](https://cloud.google.com/run/docs/authenticating/public)
- [Cloud Armor Overview (for WAFs)](https://cloud.google.com/armor/docs/overview)
- [API Gateway Overview](https://cloud.google.com/api-gateway/docs/overview)

## Challenge 5: Evasion and Exfiltration

### Introduction

Your application is now live and exposed to the internet. The final stage of your mission has two objectives: first, to achieve the "exfiltration" goal by using the application's core functionality; second, to perform this action while practicing "evasion" by analyzing the environment's security monitoring and response capabilities.

### Description

You will interact with your deployed Cloud Run service, which will lead you to the final objective: creating and running a custom machine learning job in Vertex AI. In parallel, you will act as a security analyst by investigating the project's security posture. You will check if data access is being properly audited and look for security findings in Security Command Center. Finally, you will determine if there is any automated remediation in place for these findings.
  
### Success Criteria

- You can demonstrate that Data Access audit logs for Cloud Storage are disabled.
- You have located the "Public bucket ACL" finding in Security Command Center.
- You have successfully created and run a custom Vertex AI job named cygnus-training-job using your deployed container image.
- You can demonstrate the absence of automated security response triggers related to SCC findings.

### Learning Resources

- [Creating custom training jobs (Vertex AI)](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)
- [Eventarc Overview](https://cloud.google.com/eventarc/docs/overview)
- [Security Command Center Overview](https://cloud.google.com/security-command-center/docs/)
